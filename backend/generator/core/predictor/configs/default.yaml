hydra:
  run:
    dir: generator/outputs/${now:%y-%m-%d-%H-%M-%S}
  job_logging:
    version: 1
    formatters:
      simple:
        format: "%(asctime)s | %(levelname)s | %(message)s"
    handlers:
      stream:
        class: logging.StreamHandler
        formatter: simple
        stream: ext://sys.stdout
      file:
        class: logging.FileHandler
        formatter: simple
        filename: ${hydra:run.dir}/${hydra:job.name}.log
    root:
      handlers: [stream, file]
    disable_existing_loggers: false

datamodule:
  _target_: generator.core.predictor.modules.datamodule.SequenceTargetDataModule
  csv_path: datasets/rbs/FlowSeqv2.csv
  sequence_col: RBS
  target_col: ActiveMean
  save_disk_dir: datasets/cache
  batch_size: 512
  num_workers: 4
  tokenize_kwargs:
    padding: max_length
    truncation: True
    max_length: ${model.seq_len}
    return_token_type_ids: False
  predict_mode: False
  should_load_csv: True
  sequences: null
  targets: null

model:
  _target_: generator.core.predictor.modules.lightningmodule.LightningSimpleTransformer
  vocab_size: 6
  seq_len: 31
  d_model: 128
  nhead: 4
  num_encoder_layers: 3
  dim_feedforward: 128
  dropout: 0.1
  lr: 0.001
  num_warmup_steps: 100

trainer: # ref: https://lightning.ai/docs/pytorch/stable/common/trainer.html#trainer-class-api
  _target_: lightning.pytorch.trainer.Trainer
  default_root_dir: ${hydra:run.dir}
  max_epochs: 100
  max_steps: -1
  num_sanity_val_steps: 1
  enable_progress_bar: True
  strategy: auto # ref: https://lightning.ai/docs/pytorch/stable/extensions/strategy.html
  accelerator: cpu # One of [cpu, gpu, tpu, hpu, mps, auto]
  devices: auto # One of [positive number, sequence of device indices, -1 (all available devices), auto]
  precision: 32-true
  check_val_every_n_epoch: 10
  callbacks:
    - _target_: lightning.pytorch.callbacks.ModelCheckpoint
      monitor: val_R2Score
      mode: max
      every_n_epochs: 10
      save_last: True
      save_top_k: 1
      auto_insert_metric_name: False
      filename: "epoch{epoch:03d}-R2Score{val_R2Score:.2f}"
    - _target_: lightning.pytorch.callbacks.LearningRateMonitor
      logging_interval: step
  logger:
    _target_: lightning.pytorch.loggers.TensorBoardLogger
    save_dir: ${hydra:run.dir}

inference:
  output_dir: null
  ckpt: null
